{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIY7QcXVmlxLx0jb1sBaDt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElyorS/AI-application-system/blob/main/12204556_hw5_ai_application.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Of6UDZJApnA",
        "outputId": "26712073-e409-4cd2-af46-aab330bd8c16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 17s 9ms/step - loss: 0.3991 - accuracy: 0.8947\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1952 - accuracy: 0.9435\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1420 - accuracy: 0.9592\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1104 - accuracy: 0.9684\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0882 - accuracy: 0.9758\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1002 - accuracy: 0.9683\n",
            "Test accuracy with sigmoid: 0.9682999849319458\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2859 - accuracy: 0.9180\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1386 - accuracy: 0.9594\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0931 - accuracy: 0.9726\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0678 - accuracy: 0.9803\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0516 - accuracy: 0.9853\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0813 - accuracy: 0.9742\n",
            "Test accuracy with tanh: 0.9742000102996826\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2567 - accuracy: 0.9264\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1134 - accuracy: 0.9665\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0783 - accuracy: 0.9760\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0577 - accuracy: 0.9823\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0460 - accuracy: 0.9856\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0691 - accuracy: 0.9784\n",
            "Test accuracy with relu: 0.9783999919891357\n"
          ]
        }
      ],
      "source": [
        "# Import TensorFlow and other libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist  # Corrected 'mist' to 'mnist'\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()  # Corrected 'mist' to 'mnist'\n",
        "\n",
        "# Normalize the images\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Function to create and evaluate a model with different activation functions\n",
        "def evaluate_activation(activation_function):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        tf.keras.layers.Dense(128, activation=activation_function),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(train_images, train_labels, epochs=5)\n",
        "    test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "    print(f\"Test accuracy with {activation_function}: {test_acc}\")\n",
        "\n",
        "# Evaluate models with different activation functions\n",
        "activation_functions = ['sigmoid', 'tanh', 'relu']\n",
        "for activation in activation_functions:\n",
        "    evaluate_activation(activation)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rfjoJP9zCTog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Activity 1***\n",
        "----------------------\n",
        "\n",
        "Test accuracy with sigmoid: 0.9682999849319458\n",
        "**********************************************************\n",
        "Test accuracy with tanh: 0.9742000102996826\n",
        "**********************************************************\n",
        "Test accuracy with relu: 0.9783999919891357\n",
        "**********************************************************\n",
        "All three activation functions (Sigmoid, Tanh, ReLU) resulted in models with relatively high test accuracies. The ReLU activation function performed the best in terms of accuracy, achieving nearly 97.84%, followed closely by Tanh with approximately 97.42%, and Sigmoid with approximately 96.83%. Additionally, ReLU and Tanh had similar training times per epoch, while Sigmoid took longer. These results indicate that ReLU and Tanh are well-suited for this classification task, while Sigmoid also performs reasonably well.\n"
      ],
      "metadata": {
        "id": "99mxJ6ZpBo1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate models with different learning rates\n",
        "for Ir in [0.001, 0.01, 0.1]:\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=Ir)\n",
        "  model = tf.keras. Sequential ([\n",
        "  tf.keras.layers. Flatten (input_shape=(28, 28)),\n",
        "  tf.keras. layers. Dense (128, activation= 'relu'),\n",
        "  tf.keras. layers. Dense (10, activation='softmax')\n",
        "  ])\n",
        "  model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  model.fit(train_images, train_labels, epochs=5, batch_size=32)\n",
        "  test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "  print(f\"Test accuracy with learning rate {Ir}: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0Kh0VaOGV4N",
        "outputId": "c71cc979-8d9f-472f-f45e-495ff6a4ad21"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2543 - accuracy: 0.9279\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1132 - accuracy: 0.9664\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0773 - accuracy: 0.9768\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0580 - accuracy: 0.9826\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0448 - accuracy: 0.9855\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0789 - accuracy: 0.9771\n",
            "Test accuracy with learning rate 0.001: 0.9771000146865845\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2416 - accuracy: 0.9284\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1612 - accuracy: 0.9546\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1440 - accuracy: 0.9619\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1340 - accuracy: 0.9649\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1189 - accuracy: 0.9693\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1929 - accuracy: 0.9549\n",
            "Test accuracy with learning rate 0.01: 0.9549000263214111\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 1.1578 - accuracy: 0.6773\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3041 - accuracy: 0.5836\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 1.3372 - accuracy: 0.5667\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 1.3150 - accuracy: 0.5962\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 1.2683 - accuracy: 0.5987\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 1.3801 - accuracy: 0.6059\n",
            "Test accuracy with learning rate 0.1: 0.60589998960495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate models with different learning rates\n",
        "for Ir in [0.001, 0.01, 0.1]:\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=Ir)\n",
        "  model = tf.keras. Sequential ([\n",
        "  tf.keras.layers. Flatten (input_shape=(28, 28)),\n",
        "  tf.keras. layers. Dense (128, activation= 'relu'),\n",
        "  tf.keras. layers. Dense (10, activation='softmax')\n",
        "  ])\n",
        "  model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
        "  test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "  print(f\"Test accuracy with learning rate {Ir}: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7arPiaFfHPeb",
        "outputId": "e371398a-c7a5-4907-861e-7229a13de9bc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "938/938 [==============================] - 5s 4ms/step - loss: 0.2927 - accuracy: 0.9186\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.1286 - accuracy: 0.9629\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 7s 7ms/step - loss: 0.0887 - accuracy: 0.9743\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.0671 - accuracy: 0.9797\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 8s 8ms/step - loss: 0.0529 - accuracy: 0.9841\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0744 - accuracy: 0.9770\n",
            "Test accuracy with learning rate 0.001: 0.9769999980926514\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 6s 5ms/step - loss: 0.2251 - accuracy: 0.9336\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1325 - accuracy: 0.9611\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1165 - accuracy: 0.9669\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 5s 6ms/step - loss: 0.1027 - accuracy: 0.9714\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.0899 - accuracy: 0.9751\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1617 - accuracy: 0.9628\n",
            "Test accuracy with learning rate 0.01: 0.9628000259399414\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 6s 5ms/step - loss: 0.8881 - accuracy: 0.7639\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 4s 5ms/step - loss: 0.8468 - accuracy: 0.7579\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.9581 - accuracy: 0.7114\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.8979 - accuracy: 0.7353\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.9176 - accuracy: 0.7325\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.9470 - accuracy: 0.7018\n",
            "Test accuracy with learning rate 0.1: 0.7017999887466431\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate models with different learning rates\n",
        "for Ir in [0.001, 0.01, 0.1]:\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=Ir)\n",
        "  model = tf.keras. Sequential ([\n",
        "  tf.keras.layers. Flatten (input_shape=(28, 28)),\n",
        "  tf.keras. layers. Dense (128, activation= 'relu'),\n",
        "  tf.keras. layers. Dense (10, activation='softmax')\n",
        "  ])\n",
        "  model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  model.fit(train_images, train_labels, epochs=5, batch_size=128)\n",
        "  test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "  print(f\"Test accuracy with learning rate {Ir}: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXEoaBU2HZ4h",
        "outputId": "91f02d88-bd45-4a53-ba91-1b7c75d9db9a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.3611 - accuracy: 0.8999\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.1647 - accuracy: 0.9530\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.1162 - accuracy: 0.9665\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0911 - accuracy: 0.9740\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0732 - accuracy: 0.9790\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0822 - accuracy: 0.9757\n",
            "Test accuracy with learning rate 0.001: 0.9757000207901001\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.2126 - accuracy: 0.9348\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.1091 - accuracy: 0.9672\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0888 - accuracy: 0.9729\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.0741 - accuracy: 0.9776\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0744 - accuracy: 0.9772\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.1374 - accuracy: 0.9660\n",
            "Test accuracy with learning rate 0.01: 0.9660000205039978\n",
            "Epoch 1/5\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.7582 - accuracy: 0.8447\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.4831 - accuracy: 0.8920\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.4942 - accuracy: 0.8900\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 3s 6ms/step - loss: 0.5107 - accuracy: 0.8836\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.5357 - accuracy: 0.8776\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.6650 - accuracy: 0.8762\n",
            "Test accuracy with learning rate 0.1: 0.8762000203132629\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Activity 2***\n",
        "---------------\n",
        "**********************************************************\n",
        "Batch size 32:\n",
        "------------------------------\n",
        "\n",
        "Test accuracy with learning rate 0.001: 0.9771000146865845\n",
        "\n",
        "Test accuracy with learning rate 0.01: 0.9549000263214111\n",
        "\n",
        "Test accuracy with learning rate 0.1: 0.60589998960495\n",
        "**********************************************************\n",
        "Batch size 64:\n",
        "---------------------------\n",
        "\n",
        "Test accuracy with learning rate 0.001: 0.9769999980926514\n",
        "\n",
        "Test accuracy with learning rate 0.01: 0.9628000259399414\n",
        "\n",
        "Test accuracy with learning rate 0.1: 0.7017999887466431\n",
        "**********************************************************\n",
        "Batch size 128:\n",
        "-------------------\n",
        "\n",
        "Test accuracy with learning rate 0.001: 0.9757000207901001\n",
        "\n",
        "Test accuracy with learning rate 0.01: 0.9660000205039978\n",
        "\n",
        "Test accuracy with learning rate 0.1: 0.8762000203132629\n",
        "**********************************************************\n",
        " Smaller batch size with an appropriate learning rate (such as: 0.001) appears to be a good choice for achieving higher test accuracy on this dataset.\n"
      ],
      "metadata": {
        "id": "x6ns8bhsIIyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the images\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Baseline model\n",
        "baseline_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile and train the baseline model\n",
        "baseline_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "baseline_model.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "# Evaluate the baseline model\n",
        "test_loss_baseline, test_acc_baseline = baseline_model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy for baseline model: {test_acc_baseline}\")\n",
        "\n",
        "# Model with Dropout\n",
        "model_with_dropout = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),  # Dropout layer with a dropout rate of 0.5\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile and train the model with dropout\n",
        "model_with_dropout.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model_with_dropout.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "# Evaluate the model with dropout\n",
        "test_loss_dropout, test_acc_dropout = model_with_dropout.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy for model with dropout: {test_acc_dropout}\")\n",
        "\n",
        "# Model with L2 Regularization\n",
        "model_with_l2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    tf.keras.layers.Dense(10, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
        "])\n",
        "\n",
        "# Compile and train the model with L2 regularization\n",
        "model_with_l2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model_with_l2.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "# Evaluate the model with L2 regularization\n",
        "test_loss_l2, test_acc_l2 = model_with_l2.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy for model with L2 regularization: {test_acc_l2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJpSZiP7PXIj",
        "outputId": "52ab445c-c6ff-4db1-f343-518b1819428a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2537 - accuracy: 0.9291\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1121 - accuracy: 0.9676\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0774 - accuracy: 0.9766\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0585 - accuracy: 0.9817\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0454 - accuracy: 0.9854\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0744 - accuracy: 0.9771\n",
            "Test accuracy for baseline model: 0.9771000146865845\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.3936 - accuracy: 0.8848\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2175 - accuracy: 0.9351\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1804 - accuracy: 0.9469\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1636 - accuracy: 0.9506\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1514 - accuracy: 0.9537\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0880 - accuracy: 0.9738\n",
            "Test accuracy for model with dropout: 0.973800003528595\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.8727 - accuracy: 0.8885\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.7395 - accuracy: 0.9015\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.7324 - accuracy: 0.9025\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.7285 - accuracy: 0.9029\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.7238 - accuracy: 0.9042\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.7087 - accuracy: 0.9026\n",
            "Test accuracy for model with L2 regularization: 0.9025999903678894\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Activity 3***\n",
        "------------------\n",
        "******************************************************\n",
        "Test accuracy for baseline model: 0.9771000146865845\n",
        "******************************************************\n",
        "Test accuracy for model with dropout: 0.973800003528595\n",
        "******************************************************\n",
        "Test accuracy for model with L2 regularization: 0.9025999903678894\n",
        "******************************************************************\n",
        "Baseline model achieved the highest test accuracy, indicating that, for this specific task, it performed better than the models with dropout and L2 regularization. Dropout helped prevent overfitting to some extent but had a minor impact on accuracy. On the other hand, L2 regularization, while effective at reducing overfitting, resulted in a significant decrease in test accuracy. The choice of regularization technique should be based on the trade-off between preventing overfitting and maintaining model performance."
      ],
      "metadata": {
        "id": "tpjJ6hjDRSpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Assuming you have a trained model and test data\n",
        "predictions = model.predict(test_images)\n",
        "\n",
        "# Convert probability predictions to class labels\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Calculate precision, recall, and F1-score using TensorFlow functions\n",
        "precision = tf.keras.metrics.Precision()(test_labels, predicted_labels).numpy()\n",
        "recall = tf.keras.metrics.Recall()(test_labels, predicted_labels).numpy()\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-score: {f1}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY4aA9ErRt4u",
        "outputId": "71d0e99d-5a43-4aee-db6d-06e58638c9dc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 6ms/step\n",
            "Precision: 0.9951300621032715\n",
            "Recall: 0.9967849254608154\n",
            "F1-score: 0.9959568252445301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Activity 4***\n",
        "---------------------\n",
        "*******************************************************************\n",
        "Precision - It's very high, around 99.51%. This means that when the model says something is positive, it's right nearly all the time, with very few mistakes.\n",
        "*******************************************************************\n",
        "Recall - Also very high, about 99.68%. This shows that the model is excellent at finding most of the positive things in the dataset, missing very few.\n",
        "*******************************************************************\n",
        "F1-Score - It's approximately 99.60%. This is a combination of precision and recall, showing that the model has a strong balance between being accurate when it predicts something as positive and not missing many positive things."
      ],
      "metadata": {
        "id": "KQwcEjTGSrCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the images\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Create the CNN model\n",
        "model = models.Sequential([\n",
        "   layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "   layers.MaxPooling2D((2, 2)),\n",
        "   layers.Flatten(),\n",
        "   layers.Dense(128, activation='relu'),\n",
        "   layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the CNN model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the CNN model\n",
        "model.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "# Evaluate the CNN model on the test data\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy for CNN: {test_acc}\")\n",
        "\n",
        "# Assuming you have a trained baseline feedforward neural network model\n",
        "# Evaluate the baseline model on the test data\n",
        "test_loss_baseline, test_acc_baseline = baseline_model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy for baseline feedforward NN: {test_acc_baseline}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEytQU2OTGet",
        "outputId": "14b4781e-8ee4-4b8a-f4d8-7074d92f220e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 47s 24ms/step - loss: 0.1560 - accuracy: 0.9537\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 44s 23ms/step - loss: 0.0524 - accuracy: 0.9842\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 46s 25ms/step - loss: 0.0340 - accuracy: 0.9889\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 44s 24ms/step - loss: 0.0215 - accuracy: 0.9932\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 46s 24ms/step - loss: 0.0154 - accuracy: 0.9952\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0500 - accuracy: 0.9844\n",
            "Test accuracy for CNN: 0.9843999743461609\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0744 - accuracy: 0.9771\n",
            "Test accuracy for baseline feedforward NN: 0.9771000146865845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Activity 5 ***\n",
        "---------------------\n",
        "*************************************************************\n",
        "Test accuracy for CNN: 0.9843999743461609\n",
        "*************************************************************\n",
        "Test accuracy for baseline feedforward neural netwrok model : 0.9771000146865845\n",
        "*************************************************************\n",
        "The CNN outperformed the baseline feedforward neural network in terms of accuracy, achieving a higher accuracy of 98.44% compared to 97.71%. However, the CNN required more time to train per epoch. Therefore, for this MNIST dataset, the CNN proved to be more effective in image classification."
      ],
      "metadata": {
        "id": "CWfy8ktZUiyG"
      }
    }
  ]
}