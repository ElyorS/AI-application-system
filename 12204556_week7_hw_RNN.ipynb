{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOZN98F2hlB6nIpcHaTD4tx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ElyorS/AI-application-system/blob/main/12204556_week7_hw_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Task 2.1***\n",
        "========"
      ],
      "metadata": {
        "id": "zjHna2kmHyHX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBQFdQZRHoTm",
        "outputId": "5ad82754-b128-4bdb-906f-973b316a02db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 62s 30ms/step - loss: 0.3780 - accuracy: 0.8796\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 46s 25ms/step - loss: 0.1526 - accuracy: 0.9550\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 49s 26ms/step - loss: 0.1312 - accuracy: 0.9629\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.1131 - accuracy: 0.9678\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.1029 - accuracy: 0.9709\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.1074 - accuracy: 0.9691\n",
            "Test accuracy: 0.9690999984741211\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the images\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Initialize the RNN model with Dropout and Batch Normalization\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(128, activation='relu', return_sequences=True, input_shape=(28, 28)),\n",
        "    tf.keras.layers.BatchNormalization(),  # Add Batch Normalization\n",
        "    tf.keras.layers.SimpleRNN(128, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),  # Add Batch Normalization\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(\"Test accuracy:\", test_acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code adds Batch Normalization layers to the RNN model to improve generalization and training speed. You can also add Dropout layers if you want to experiment with further regularization.\n",
        "\n",
        "Test accuracy: 0.9690999984741211"
      ],
      "metadata": {
        "id": "x8QF9U8CH4nV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Task 2.2***\n",
        "=============="
      ],
      "metadata": {
        "id": "8u2w44hwIA3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the images\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Define a list of activation functions to experiment with\n",
        "activation_functions = ['relu', 'tanh', 'sigmoid']\n",
        "\n",
        "for activation_function in activation_functions:\n",
        "    # Initialize the RNN model with the specified activation function\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.SimpleRNN(128, activation=activation_function, return_sequences=True, input_shape=(28, 28)),\n",
        "        tf.keras.layers.SimpleRNN(128, activation=activation_function),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "    # Evaluate the model\n",
        "    test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "    print(f\"Activation Function: {activation_function}\")\n",
        "    print(\"Test accuracy:\", test_acc)\n",
        "    print(\"------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLgRsREGIAOR",
        "outputId": "c76fe6e8-37fb-418b-9f0c-82192edd2ce0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 0.3433 - accuracy: 0.8916\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 37s 20ms/step - loss: 0.1502 - accuracy: 0.9586\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 38s 21ms/step - loss: 0.1231 - accuracy: 0.9660\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 0.1065 - accuracy: 0.9707\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0976 - accuracy: 0.9732\n",
            "313/313 [==============================] - 2s 7ms/step - loss: 0.0951 - accuracy: 0.9725\n",
            "Activation Function: relu\n",
            "Test accuracy: 0.9725000262260437\n",
            "------------------\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 41s 21ms/step - loss: 0.3170 - accuracy: 0.9045\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 43s 23ms/step - loss: 0.1912 - accuracy: 0.9446\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 0.1694 - accuracy: 0.9508\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 45s 24ms/step - loss: 0.1562 - accuracy: 0.9551\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.1537 - accuracy: 0.9565\n",
            "313/313 [==============================] - 4s 10ms/step - loss: 0.1896 - accuracy: 0.9436\n",
            "Activation Function: tanh\n",
            "Test accuracy: 0.9435999989509583\n",
            "------------------\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 44s 22ms/step - loss: 1.4409 - accuracy: 0.4609\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 39s 21ms/step - loss: 0.7354 - accuracy: 0.7433\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 0.4910 - accuracy: 0.8374\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.3453 - accuracy: 0.8949\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 38s 21ms/step - loss: 0.2735 - accuracy: 0.9181\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.2645 - accuracy: 0.9226\n",
            "Activation Function: sigmoid\n",
            "Test accuracy: 0.9225999712944031\n",
            "------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test accuracy with Relu: 0.9725000262260437\n",
        "________________________\n",
        "Test accuracy with Tanh: 0.9435999989509583\n",
        "________________________\n",
        "Test accuracy with Sigmoid: 0.9225999712944031"
      ],
      "metadata": {
        "id": "V5OMddjfKzpd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, I iterated through three different activation functions (ReLU, tanh, and sigmoid) and train a separate RNN model for each. After training, we evaluate and print the test accuracy for each activation function.\n",
        "The impact of activation functions on RNN performance can vary, and it's important to experiment with different functions to see which one works best for your specific problem. In. this case, Relu had the best accurasy, followed by Tanh and Sigmoid."
      ],
      "metadata": {
        "id": "ceGB39x0IGfn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Task 2.3***\n",
        "============"
      ],
      "metadata": {
        "id": "hmx2QP3MIQFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the images\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Initialize the RNN model with more RNN layers\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(128, activation='relu', return_sequences=True, input_shape=(28, 28)),\n",
        "    tf.keras.layers.SimpleRNN(128, activation='relu', return_sequences=True),  # Add another RNN layer\n",
        "    tf.keras.layers.SimpleRNN(128, activation='relu', return_sequences=True),  # Add another RNN layer\n",
        "    tf.keras.layers.SimpleRNN(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(\"Test accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHxCiLsaIVsF",
        "outputId": "5ec1ecf0-ee6f-4c73-c52e-4218f222fe49"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 94s 49ms/step - loss: 0.2983 - accuracy: 0.9094\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1382 - accuracy: 0.9620\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 82s 44ms/step - loss: 0.1186 - accuracy: 0.9674\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.1048 - accuracy: 0.9710\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0973 - accuracy: 0.9735\n",
            "313/313 [==============================] - 5s 13ms/step - loss: 0.1059 - accuracy: 0.9710\n",
            "Test accuracy: 0.9710000157356262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, I have added two more SimpleRNN layers to the RNN model, making it deeper. This allows the model to potentially recognize more complex sequential patterns. The impact of adding more layers may vary depending on the specific dataset and problem.\n",
        "\n",
        "Test accuracy: 0.9710000157356262"
      ],
      "metadata": {
        "id": "3rupIwysIYt1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2.4"
      ],
      "metadata": {
        "id": "5xwxD_bCIfJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the images\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Define a list of optimizers to experiment with\n",
        "optimizers = ['sgd', 'rmsprop', 'adam']\n",
        "\n",
        "for optimizer in optimizers:\n",
        "    # Initialize the RNN model\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.SimpleRNN(128, activation='relu', return_sequences=True, input_shape=(28, 28)),\n",
        "        tf.keras.layers.SimpleRNN(128, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model with the specified optimizer\n",
        "    if optimizer == 'sgd':\n",
        "        optimizer_obj = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "    elif optimizer == 'rmsprop':\n",
        "        optimizer_obj = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "    else:  # Default to Adam\n",
        "        optimizer_obj = 'adam'\n",
        "\n",
        "    model.compile(optimizer=optimizer_obj, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "    # Evaluate the model\n",
        "    test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "    print(f\"Optimizer: {optimizer}\")\n",
        "    print(\"Test accuracy:\", test_acc)\n",
        "    print(\"------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_ijiXUZIetP",
        "outputId": "45dc8fc8-a106-4848-c81a-e00c1cf9cc9d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 38s 19ms/step - loss: 0.6743 - accuracy: 0.7746\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.1766 - accuracy: 0.9474\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.1255 - accuracy: 0.9625\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 0.1026 - accuracy: 0.9692\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 36s 19ms/step - loss: 0.0855 - accuracy: 0.9746\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.1094 - accuracy: 0.9680\n",
            "Optimizer: sgd\n",
            "Test accuracy: 0.9679999947547913\n",
            "------------------\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 38s 19ms/step - loss: 0.3524 - accuracy: 0.8891\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.1497 - accuracy: 0.9586\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.1215 - accuracy: 0.9682\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 37s 20ms/step - loss: 0.1087 - accuracy: 0.9720\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 35s 19ms/step - loss: 0.1060 - accuracy: 0.9744\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 0.1031 - accuracy: 0.9743\n",
            "Optimizer: rmsprop\n",
            "Test accuracy: 0.9743000268936157\n",
            "------------------\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 41s 21ms/step - loss: 0.3520 - accuracy: 0.8882\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 0.1432 - accuracy: 0.9592\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 42s 22ms/step - loss: 0.1176 - accuracy: 0.9674\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 0.1043 - accuracy: 0.9707\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 40s 21ms/step - loss: 0.0993 - accuracy: 0.9723\n",
            "313/313 [==============================] - 3s 10ms/step - loss: 0.0936 - accuracy: 0.9746\n",
            "Optimizer: adam\n",
            "Test accuracy: 0.9746000170707703\n",
            "------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test accuracy with sgd: 0.9679999947547913\n",
        "__________________\n",
        "Test accuracy with rmsprop: 0.9743000268936157\n",
        "__________________\n",
        "Test accuracy with adam: 0.9746000170707703"
      ],
      "metadata": {
        "id": "8R6grK4KRBm3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, I have used three different optimizers (SGD, RMSprop, and Adam), train a separate RNN model for each optimizer, and evaluate and print the test accuracy.\n",
        "Different optimizers can significantly affect training speed and performance, so it's important to experiment with various optimizers to find the one that works best for your specific problem. In this case, Adam had the best accuracy followed by rmsprop and sgd."
      ],
      "metadata": {
        "id": "VJSoQm3gIlTP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Task 2.5***\n",
        "=============\n"
      ],
      "metadata": {
        "id": "XnBhgna6JgT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the images\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "# Initialize the RNN model (you can choose any variant from the previous tasks)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.SimpleRNN(128, activation='relu', return_sequences=True, input_shape=(28, 28)),\n",
        "    tf.keras.layers.SimpleRNN(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model (you can use any optimizer or configuration as needed)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model (you can choose the number of epochs as needed)\n",
        "model.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "# Evaluate the model with test data\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyIQWMzTJi-3",
        "outputId": "e54325e5-a706-4f27-8415-1295c68b3499"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 50s 26ms/step - loss: 0.3361 - accuracy: 0.8952\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.1462 - accuracy: 0.9587\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 42s 23ms/step - loss: 0.1199 - accuracy: 0.9661\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 43s 23ms/step - loss: 0.1109 - accuracy: 0.9693\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 38s 20ms/step - loss: 0.1007 - accuracy: 0.9716\n",
            "313/313 [==============================] - 3s 7ms/step - loss: 0.0886 - accuracy: 0.9736\n",
            "Test accuracy: 0.9735999703407288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, I loaded the trained RNN model, evaluated it using the test dataset, and printed the test loss and test accuracy.\n",
        "This task is important to assess how well the RNN model generalizes to unseen data and provides insights into its overall performance.\n",
        "\n",
        "0.9735999703407288\n",
        "\n"
      ],
      "metadata": {
        "id": "GCs6SfSIKMVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "miRdJLGeIlRt"
      }
    }
  ]
}